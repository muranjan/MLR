{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "style = {'description_width': 'initial'}\n",
    "\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6BZ-jLOunczC"
   },
   "outputs": [],
   "source": [
    "#1 Importing essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WKtERLr9n09B"
   },
   "outputs": [],
   "source": [
    "#2 Importing the dataset\n",
    "#file_name = 'beer_data.csv'\n",
    "\n",
    "data_url='https://raw.githubusercontent.com/muranjan/datarepo/master/beer_data.csv'\n",
    "dataset = pd.read_csv(data_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABV</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Cellar Temperature</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.5</td>\n",
       "      <td>1</td>\n",
       "      <td>40-45</td>\n",
       "      <td>4.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.3</td>\n",
       "      <td>22</td>\n",
       "      <td>40-45</td>\n",
       "      <td>3.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>45-50</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>1</td>\n",
       "      <td>35-40</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.9</td>\n",
       "      <td>1</td>\n",
       "      <td>45-50</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.9</td>\n",
       "      <td>32</td>\n",
       "      <td>40-45</td>\n",
       "      <td>4.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.7</td>\n",
       "      <td>141</td>\n",
       "      <td>35-40</td>\n",
       "      <td>3.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.6</td>\n",
       "      <td>1</td>\n",
       "      <td>40-45</td>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>40-45</td>\n",
       "      <td>3.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.4</td>\n",
       "      <td>12</td>\n",
       "      <td>40-45</td>\n",
       "      <td>3.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ABV  Ratings Cellar Temperature  Score\n",
       "0  7.5        1              40-45   4.08\n",
       "1  5.3       22              40-45   3.82\n",
       "2  9.0        1              45-50   4.03\n",
       "3  4.6        1              35-40   4.00\n",
       "4  6.9        1              45-50   3.75\n",
       "5  7.9       32              40-45   4.26\n",
       "6  4.7      141              35-40   3.47\n",
       "7  5.6        1              40-45   3.70\n",
       "8  5.0        1              40-45   3.90\n",
       "9  5.4       12              40-45   3.79"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaying the dataset\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 1631 rows and 4 columns.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset has {dataset.shape[0]} rows and {dataset.shape[1]} columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Nulls and Fill Nulls Based on Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ABV                   0\n",
       "Ratings               0\n",
       "Cellar Temperature    0\n",
       "Score                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check nulls..\n",
    "\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[~dataset['Cellar Temperature'].isna()]\n",
    "dataset.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['ABV'].fillna(dataset['ABV'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset['Ratings'] = dataset['Ratings'].apply(lambda x : np.float32(x.replace(\",\", \"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with the categorical data\n",
    "\n",
    "# Spliting Cellar Temperature into Maximum and Minimum based on the given data and converting the type from str to int\n",
    "\n",
    "dataset.loc[:, 'Minimum_Cellar_Temp'] = dataset['Cellar Temperature'].apply(lambda x : int(str(x).split('-')[0].strip()))\n",
    "dataset.loc[:, 'Maximum_Cellar_Temp'] = dataset['Cellar Temperature'].apply(lambda x : int(str(x).split('-')[1].strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ABV', 'Ratings', 'Score', 'Minimum_Cellar_Temp', 'Maximum_Cellar_Temp']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.drop('Cellar Temperature', inplace=True, axis=1)\n",
    "\n",
    "#New dataset with selected features\n",
    "#dataset = dataset[['ABV', 'Ratings','Minimum_Cellar_Temp','Maximum_Cellar_Temp', 'Score']]\n",
    "\n",
    "dataset.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G5WuUWRFn4j8"
   },
   "outputs": [],
   "source": [
    "#3 classify dependent and independent variables\n",
    "X = dataset[[col for col in dataset.columns if col not in ('Score')]].values  #independent variables \n",
    "y = dataset['Score'].values  #dependent variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-bZ82kVbn7Ga"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Idependent Variables :\n",
      "\n",
      " [[ 7.5  1.  40.  45. ]\n",
      " [ 5.3 22.  40.  45. ]\n",
      " [ 9.   1.  45.  50. ]\n",
      " [ 4.6  1.  35.  40. ]\n",
      " [ 6.9  1.  45.  50. ]]\n",
      "\n",
      "Dependent Variable (Score):\n",
      "\n",
      " [4.08 3.82 4.03 4.   3.75]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nIdependent Variables :\\n\\n\", X[:5])\n",
    "print(\"\\nDependent Variable (Score):\\n\\n\", y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BFMIwI5Zn9MX"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df67c4c2a44e40f0afd14fd14b50c7bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.2, description='Test Size :', max=0.6, min=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#4 Creating training set and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "test_size = widgets.FloatSlider(min=0.01, max=0.6, value=0.2, description=\"Test Size :\", tooltips=['Usually 20-30%'])\n",
    "display(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide the dataset into Train and Test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X ,y, test_size=test_size.value, random_state = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YcY06YGDn_dz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set :\n",
      "----------------\n",
      "\n",
      "X = \n",
      " [[ 5.2  5.  40.  45. ]\n",
      " [ 5.6  1.  35.  40. ]\n",
      " [ 4.8  2.  40.  45. ]\n",
      " [ 6.5  3.  40.  45. ]\n",
      " [ 5.1  0.  40.  45. ]]\n",
      "y = \n",
      " [3.79 3.9  3.44 3.21 0.  ]\n",
      "\n",
      "\n",
      "Test Set :\n",
      "----------------\n",
      "\n",
      "X = \n",
      " [[ 4.8  2.  35.  40. ]\n",
      " [ 5.1  0.  35.  40. ]\n",
      " [ 4.   3.  40.  45. ]\n",
      " [ 7.5  3.  45.  50. ]\n",
      " [10.6  2.  45.  50. ]]\n",
      "y = \n",
      " [3.13 0.   2.82 3.91 4.38]\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set :\\n----------------\\n\")\n",
    "print(\"X = \\n\", X_train[:5])\n",
    "print(\"y = \\n\", y_train[:5])\n",
    "\n",
    "print(\"\\n\\nTest Set :\\n----------------\\n\")\n",
    "print(\"X = \\n\",X_test[:5])\n",
    "print(\"y = \\n\", y_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training set is (1304, 4)\n",
      "Shape of Testing set is (327, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of Training set is {X_train.shape}\")\n",
    "print(f\"Shape of Testing set is {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Support Vector Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import support vector library\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and Evaluate the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8XbYFyk8oCrH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions =  [3.87158722 0.09534496 3.66120693 3.88271879 4.17896989 3.57462616\n",
      " 3.71518472 0.09267043 3.83997801 3.58285154 3.72509269 3.57013683\n",
      " 3.24663481 3.71633733 3.57640345 3.75334967 3.75960791 3.86755239\n",
      " 3.87297783 3.79999041 4.11208339 4.21468538 0.06919579 3.5697965\n",
      " 3.5732781  0.92045952 3.92992621 3.60480767 3.84983296 3.91002229\n",
      " 3.744829   0.93154106 3.78525353 0.09627126 4.01162825 3.84586508\n",
      " 3.76224802 3.73020408 3.74027044 3.32529312 3.73310039 3.80514986\n",
      " 3.72509269 4.2284756  3.75161917 4.07548163 3.5697965  3.178862\n",
      " 3.38291591 4.05524978 3.93950443 3.58285154 4.05868202 3.94021578\n",
      " 3.67440595 3.73310039 0.09708641 3.79981332 3.78970317 3.63084579\n",
      " 3.60012073 3.84364282 3.72192536 0.10027302 3.46353756 4.27119602\n",
      " 3.67603143 3.6618162  3.69829291 3.5697965  3.95242528 3.91603431\n",
      " 3.33042942 3.93357794 3.96309561 3.93425023 3.5467629  3.72909462\n",
      " 4.0359174  3.70910729 3.74812125 3.70280664 3.56446058 3.66538873\n",
      " 4.27622616 3.46025526 3.75161917 0.17021601 4.00020386 3.57706198\n",
      " 3.76488681 3.32529312 0.92045952 4.07548163 0.1005397  3.55062094\n",
      " 3.5848276  3.45059197 3.92008039 3.51049811 3.90884567 3.62668237\n",
      " 3.76836664 3.55282558 3.77789911 3.56838931 3.58238202 3.56779392\n",
      " 4.0224885  3.79981332 3.72329734 3.75161917 3.56966207 3.64259306\n",
      " 0.06919579 3.8868434  3.71388627 3.49661807 3.61787102 3.8979626\n",
      " 4.08221077 0.14089089 4.04299511 3.77789911 3.51633427 3.25183438\n",
      " 3.5199875  3.7483681  3.78406385 4.30609893 3.956793   0.09328477\n",
      " 3.61988627 3.56849733 3.5689335  3.86295952 4.02841554 3.57046232\n",
      " 3.79449851 3.73663156 4.42450592 3.55322309 3.65245561 0.09267043\n",
      " 3.9945613  3.53168045 3.5697965  3.55987846 4.17742628 3.43235853\n",
      " 2.96984393 0.08081963 0.09188238 3.1932947  0.07919779 3.67135967\n",
      " 0.09020569 0.09480467 3.77946499 3.88160925 3.24303335 3.84983296\n",
      " 3.5697965  3.69007852 3.9938434  4.19121817 3.58285154 3.91037634\n",
      " 3.58125916 4.03973815 3.72978736 3.63375879 3.87843591 3.79292309\n",
      " 3.57840886 3.84882301 3.5697965  3.87306164 3.58932929 3.9003026\n",
      " 3.51990358 3.57462616 3.83310412 3.55728295 0.1000901  3.27094376\n",
      " 3.68161446 3.61474738 3.89412752 3.5697965  1.08148195 3.56979651\n",
      " 3.75148136 3.9293517  0.09267043 4.28300225 3.68161446 3.92550716\n",
      " 3.87306164 3.58692296 3.60231733 3.55985443 3.72727201 3.58510121\n",
      " 3.5697965  3.96749238 3.83310412 0.07207429 3.71265758 0.09708641\n",
      " 3.5697794  3.60443524 3.57462616 0.09482981 3.88957351 4.02044595\n",
      " 0.09482981 0.09020569 3.75334967 3.66972147 3.77789911 3.62230887\n",
      " 3.64259306 0.92045952 3.04101107 0.09708641 3.74970218 3.93304561\n",
      " 3.6810268  3.99038244 0.10738769 3.85209857 3.79449851 0.07207429\n",
      " 0.93191755 3.66962673 3.87158722 3.57823378 3.56977945 3.78238863\n",
      " 3.82580151 3.44128065 3.72978736 3.59635402 3.55985443 4.04925261\n",
      " 0.14089089 3.39974449 3.85031825 3.8868434  3.68641767 3.49239447\n",
      " 3.3423501  1.27540736 3.2796475  3.97797731 3.64259306 3.60810121\n",
      " 3.95510166 4.05524978 3.56557548 0.09267043 3.5697965  3.96781725\n",
      " 3.76498808 3.57184302 3.96781767 3.8627333  3.67484867 4.02274817\n",
      " 0.09351977 3.79264387 3.71983197 3.61787102 3.66560578 3.92992621\n",
      " 3.51049811 3.78417785 4.2177675  3.50701992 3.34777806 3.56319699\n",
      " 4.25480506 3.31139854 3.53993936 3.76109096 0.07207429 3.94008941\n",
      " 3.57011233 3.56978692 3.60883799 0.09534496 0.10738769 4.3832537\n",
      " 3.71014623 3.17399954 3.6400184  3.72978736 3.52468634 0.15044522\n",
      " 4.03001955 3.96781767 0.08081963 3.97853533 3.72303925 3.96523595\n",
      " 3.63084579 3.70212946 3.71422112 3.84582256 3.27566776 3.53993936\n",
      " 3.16319266 3.82040642 3.75161917 3.96781767 3.76654966 3.15244879\n",
      " 3.90884567 3.31890761 3.8938726  3.79806932 3.76976256 3.91185445\n",
      " 0.09534496 3.89081567 3.90823116]\n"
     ]
    }
   ],
   "source": [
    "# Train the Regressor with training set\n",
    "regressor = SVR()\n",
    "\n",
    "#fit the linear model\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "#7 predict the outcome of test sets\n",
    "y_Pred = regressor.predict(X_test)\n",
    "print(\"\\nPredictions = \", y_Pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZAwiJVWuoHEX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------\n",
      "RMLSE Score =  0.9334725731316009\n",
      "\n",
      "Actual vs Predicted Scores \n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Abs. Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.13</td>\n",
       "      <td>3.871587</td>\n",
       "      <td>0.741587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.095345</td>\n",
       "      <td>0.095345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.82</td>\n",
       "      <td>3.661207</td>\n",
       "      <td>0.841207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.91</td>\n",
       "      <td>3.882719</td>\n",
       "      <td>0.027281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.38</td>\n",
       "      <td>4.178970</td>\n",
       "      <td>0.201030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.25</td>\n",
       "      <td>3.574626</td>\n",
       "      <td>0.675374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.82</td>\n",
       "      <td>3.715185</td>\n",
       "      <td>0.104815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.092670</td>\n",
       "      <td>0.092670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.49</td>\n",
       "      <td>3.839978</td>\n",
       "      <td>0.349978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.00</td>\n",
       "      <td>3.582852</td>\n",
       "      <td>1.582852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.40</td>\n",
       "      <td>3.725093</td>\n",
       "      <td>0.325093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.53</td>\n",
       "      <td>3.570137</td>\n",
       "      <td>0.040137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.89</td>\n",
       "      <td>3.246635</td>\n",
       "      <td>0.643365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.64</td>\n",
       "      <td>3.716337</td>\n",
       "      <td>0.076337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.84</td>\n",
       "      <td>3.576403</td>\n",
       "      <td>0.263597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.17</td>\n",
       "      <td>3.753350</td>\n",
       "      <td>0.416650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.71</td>\n",
       "      <td>3.759608</td>\n",
       "      <td>0.049608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.31</td>\n",
       "      <td>3.867552</td>\n",
       "      <td>0.442448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.90</td>\n",
       "      <td>3.872978</td>\n",
       "      <td>0.027022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.00</td>\n",
       "      <td>3.799990</td>\n",
       "      <td>0.799990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.83</td>\n",
       "      <td>4.112083</td>\n",
       "      <td>0.282083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.43</td>\n",
       "      <td>4.214685</td>\n",
       "      <td>0.784685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.069196</td>\n",
       "      <td>0.069196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3.98</td>\n",
       "      <td>3.569797</td>\n",
       "      <td>0.410203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3.81</td>\n",
       "      <td>3.573278</td>\n",
       "      <td>0.236722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.920460</td>\n",
       "      <td>0.920460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3.84</td>\n",
       "      <td>3.929926</td>\n",
       "      <td>0.089926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3.72</td>\n",
       "      <td>3.604808</td>\n",
       "      <td>0.115192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.97</td>\n",
       "      <td>3.849833</td>\n",
       "      <td>0.879833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.12</td>\n",
       "      <td>3.910022</td>\n",
       "      <td>0.209978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>3.79</td>\n",
       "      <td>3.729787</td>\n",
       "      <td>0.060213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>4.10</td>\n",
       "      <td>3.524686</td>\n",
       "      <td>0.575314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.150445</td>\n",
       "      <td>0.150445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>4.28</td>\n",
       "      <td>4.030020</td>\n",
       "      <td>0.249980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>3.67</td>\n",
       "      <td>3.967818</td>\n",
       "      <td>0.297818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.080820</td>\n",
       "      <td>0.080820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>3.94</td>\n",
       "      <td>3.978535</td>\n",
       "      <td>0.038535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>4.35</td>\n",
       "      <td>3.723039</td>\n",
       "      <td>0.626961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>3.94</td>\n",
       "      <td>3.965236</td>\n",
       "      <td>0.025236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>3.43</td>\n",
       "      <td>3.630846</td>\n",
       "      <td>0.200846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>4.08</td>\n",
       "      <td>3.702129</td>\n",
       "      <td>0.377871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>3.61</td>\n",
       "      <td>3.714221</td>\n",
       "      <td>0.104221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>4.47</td>\n",
       "      <td>3.845823</td>\n",
       "      <td>0.624177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>3.83</td>\n",
       "      <td>3.275668</td>\n",
       "      <td>0.554332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>3.15</td>\n",
       "      <td>3.539939</td>\n",
       "      <td>0.389939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>3.96</td>\n",
       "      <td>3.163193</td>\n",
       "      <td>0.796807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>3.71</td>\n",
       "      <td>3.820406</td>\n",
       "      <td>0.110406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>4.25</td>\n",
       "      <td>3.751619</td>\n",
       "      <td>0.498381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>3.50</td>\n",
       "      <td>3.967818</td>\n",
       "      <td>0.467818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>4.04</td>\n",
       "      <td>3.766550</td>\n",
       "      <td>0.273450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>4.00</td>\n",
       "      <td>3.152449</td>\n",
       "      <td>0.847551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>3.52</td>\n",
       "      <td>3.908846</td>\n",
       "      <td>0.388846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>4.39</td>\n",
       "      <td>3.318908</td>\n",
       "      <td>1.071092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>3.77</td>\n",
       "      <td>3.893873</td>\n",
       "      <td>0.123873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>4.15</td>\n",
       "      <td>3.798069</td>\n",
       "      <td>0.351931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>2.96</td>\n",
       "      <td>3.769763</td>\n",
       "      <td>0.809763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>4.13</td>\n",
       "      <td>3.911854</td>\n",
       "      <td>0.218146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.095345</td>\n",
       "      <td>0.095345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>4.05</td>\n",
       "      <td>3.890816</td>\n",
       "      <td>0.159184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>4.14</td>\n",
       "      <td>3.908231</td>\n",
       "      <td>0.231769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>327 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual  Predicted  Abs. Error\n",
       "0      3.13   3.871587    0.741587\n",
       "1      0.00   0.095345    0.095345\n",
       "2      2.82   3.661207    0.841207\n",
       "3      3.91   3.882719    0.027281\n",
       "4      4.38   4.178970    0.201030\n",
       "5      4.25   3.574626    0.675374\n",
       "6      3.82   3.715185    0.104815\n",
       "7      0.00   0.092670    0.092670\n",
       "8      3.49   3.839978    0.349978\n",
       "9      2.00   3.582852    1.582852\n",
       "10     3.40   3.725093    0.325093\n",
       "11     3.53   3.570137    0.040137\n",
       "12     3.89   3.246635    0.643365\n",
       "13     3.64   3.716337    0.076337\n",
       "14     3.84   3.576403    0.263597\n",
       "15     4.17   3.753350    0.416650\n",
       "16     3.71   3.759608    0.049608\n",
       "17     4.31   3.867552    0.442448\n",
       "18     3.90   3.872978    0.027022\n",
       "19     3.00   3.799990    0.799990\n",
       "20     3.83   4.112083    0.282083\n",
       "21     3.43   4.214685    0.784685\n",
       "22     0.00   0.069196    0.069196\n",
       "23     3.98   3.569797    0.410203\n",
       "24     3.81   3.573278    0.236722\n",
       "25     0.00   0.920460    0.920460\n",
       "26     3.84   3.929926    0.089926\n",
       "27     3.72   3.604808    0.115192\n",
       "28     2.97   3.849833    0.879833\n",
       "29     4.12   3.910022    0.209978\n",
       "..      ...        ...         ...\n",
       "297    3.79   3.729787    0.060213\n",
       "298    4.10   3.524686    0.575314\n",
       "299    0.00   0.150445    0.150445\n",
       "300    4.28   4.030020    0.249980\n",
       "301    3.67   3.967818    0.297818\n",
       "302    0.00   0.080820    0.080820\n",
       "303    3.94   3.978535    0.038535\n",
       "304    4.35   3.723039    0.626961\n",
       "305    3.94   3.965236    0.025236\n",
       "306    3.43   3.630846    0.200846\n",
       "307    4.08   3.702129    0.377871\n",
       "308    3.61   3.714221    0.104221\n",
       "309    4.47   3.845823    0.624177\n",
       "310    3.83   3.275668    0.554332\n",
       "311    3.15   3.539939    0.389939\n",
       "312    3.96   3.163193    0.796807\n",
       "313    3.71   3.820406    0.110406\n",
       "314    4.25   3.751619    0.498381\n",
       "315    3.50   3.967818    0.467818\n",
       "316    4.04   3.766550    0.273450\n",
       "317    4.00   3.152449    0.847551\n",
       "318    3.52   3.908846    0.388846\n",
       "319    4.39   3.318908    1.071092\n",
       "320    3.77   3.893873    0.123873\n",
       "321    4.15   3.798069    0.351931\n",
       "322    2.96   3.769763    0.809763\n",
       "323    4.13   3.911854    0.218146\n",
       "324    0.00   0.095345    0.095345\n",
       "325    4.05   3.890816    0.159184\n",
       "326    4.14   3.908231    0.231769\n",
       "\n",
       "[327 rows x 3 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating score from Root Mean Log Squared Error\n",
    "def rmlse(y_test, y_pred):\n",
    "    error = np.square(np.log10(y_pred +1) - np.log10(y_test +1)).mean() ** 0.5\n",
    "    score = 1 - error\n",
    "    return score\n",
    "\n",
    "# Printing the score\n",
    "print(\"\\n----------------------------\\nRMLSE Score = \", rmlse(y_test, y_Pred))\n",
    "\n",
    "#9 Comparing Actual and Predicted Salaries for he test set\n",
    "print(\"\\nActual vs Predicted Scores \\n------------------------------\\n\")\n",
    "error_df = pd.DataFrame({\"Actual\" : y_test,\n",
    "                         \"Predicted\" : y_Pred,\n",
    "                         \"Abs. Error\" : np.abs(y_test - y_Pred)})\n",
    "\n",
    "error_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual vs. Predicted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting Actual observation vs Predictions\n",
    "plt.scatter(y_test, y_Pred, s = 70)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "#plt.legend()\n",
    "plt.grid();\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LinearRegression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
