{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "style = {'description_width': 'initial'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6BZ-jLOunczC"
   },
   "outputs": [],
   "source": [
    "#1 Importing essential libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WKtERLr9n09B"
   },
   "outputs": [],
   "source": [
    "#2 Importing the dataset\n",
    "\n",
    "file_url = 'https://raw.githubusercontent.com/muranjan/datarepo/master/beer_data.csv'\n",
    "dataset = pd.read_csv(file_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ABV</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Cellar Temperature</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.5</td>\n",
       "      <td>1</td>\n",
       "      <td>40-45</td>\n",
       "      <td>4.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.3</td>\n",
       "      <td>22</td>\n",
       "      <td>40-45</td>\n",
       "      <td>3.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "      <td>45-50</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>1</td>\n",
       "      <td>35-40</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.9</td>\n",
       "      <td>1</td>\n",
       "      <td>45-50</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7.9</td>\n",
       "      <td>32</td>\n",
       "      <td>40-45</td>\n",
       "      <td>4.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.7</td>\n",
       "      <td>141</td>\n",
       "      <td>35-40</td>\n",
       "      <td>3.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.6</td>\n",
       "      <td>1</td>\n",
       "      <td>40-45</td>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ABV  Ratings Cellar Temperature  Score\n",
       "0  7.5        1              40-45   4.08\n",
       "1  5.3       22              40-45   3.82\n",
       "2  9.0        1              45-50   4.03\n",
       "3  4.6        1              35-40   4.00\n",
       "4  6.9        1              45-50   3.75\n",
       "5  7.9       32              40-45   4.26\n",
       "6  4.7      141              35-40   3.47\n",
       "7  5.6        1              40-45   3.70"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displaying the dataset\n",
    "dataset.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has 1631 rows and 4 columns.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset has {dataset.shape[0]} rows and {dataset.shape[1]} columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop Nulls and Fill Nulls Based on Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ABV                   0\n",
       "Ratings               0\n",
       "Cellar Temperature    0\n",
       "Score                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check nulls..\n",
    "\n",
    "dataset.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[~dataset['Cellar Temperature'].isna()]\n",
    "dataset.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['ABV'].fillna(dataset['ABV'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset['Ratings'] = dataset['Ratings'].apply(lambda x : np.float32(x.replace(\",\", \"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dealing with the categorical data\n",
    "\n",
    "# Spliting Cellar Temperature into Maximum and Minimum based on the given data and converting the type from str to int\n",
    "\n",
    "dataset.loc[:, 'Minimum_Cellar_Temp'] = dataset['Cellar Temperature'].apply(lambda x : int(str(x).split('-')[0].strip()))\n",
    "dataset.loc[:, 'Maximum_Cellar_Temp'] = dataset['Cellar Temperature'].apply(lambda x : int(str(x).split('-')[1].strip()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ABV', 'Ratings', 'Score', 'Minimum_Cellar_Temp', 'Maximum_Cellar_Temp']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.drop('Cellar Temperature', inplace=True, axis=1)\n",
    "dataset.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G5WuUWRFn4j8"
   },
   "outputs": [],
   "source": [
    "#3 classify dependent and independent variables\n",
    "X = dataset[[col for col in dataset.columns if col not in ('Score')]].values  #independent variables \n",
    "y = dataset['Score'].values  #dependent variable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-bZ82kVbn7Ga"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Idependent Variables :\n",
      "\n",
      " [[ 7.5  1.  40.  45. ]\n",
      " [ 5.3 22.  40.  45. ]\n",
      " [ 9.   1.  45.  50. ]\n",
      " [ 4.6  1.  35.  40. ]\n",
      " [ 6.9  1.  45.  50. ]]\n",
      "\n",
      "Dependent Variable (Score):\n",
      "\n",
      " [4.08 3.82 4.03 4.   3.75]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nIdependent Variables :\\n\\n\", X[:5])\n",
    "print(\"\\nDependent Variable (Score):\\n\\n\", y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BFMIwI5Zn9MX"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0cf15fb01d1426b809306441ff7794e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=0.2, description='Test Size :', max=0.6, min=0.01)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#4 Creating training set and testing set\n",
    "from sklearn.model_selection import train_test_split\n",
    "test_size = widgets.FloatSlider(min=0.01, max=0.6, value=0.2, description=\"Test Size :\", tooltips=['Usually 20-30%'])\n",
    "display(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide the dataset into Train and Test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X ,y, test_size=test_size.value, random_state = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YcY06YGDn_dz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set :\n",
      "----------------\n",
      "\n",
      "X = \n",
      " [[ 5.2  5.  40.  45. ]\n",
      " [ 5.6  1.  35.  40. ]\n",
      " [ 4.8  2.  40.  45. ]\n",
      " [ 6.5  3.  40.  45. ]\n",
      " [ 5.1  0.  40.  45. ]]\n",
      "y = \n",
      " [3.79 3.9  3.44 3.21 0.  ]\n",
      "\n",
      "\n",
      "Test Set :\n",
      "----------------\n",
      "\n",
      "X = \n",
      " [[ 4.8  2.  35.  40. ]\n",
      " [ 5.1  0.  35.  40. ]\n",
      " [ 4.   3.  40.  45. ]\n",
      " [ 7.5  3.  45.  50. ]\n",
      " [10.6  2.  45.  50. ]]\n",
      "y = \n",
      " [3.13 0.   2.82 3.91 4.38]\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Set :\\n----------------\\n\")\n",
    "print(\"X = \\n\", X_train[:5])\n",
    "print(\"y = \\n\", y_train[:5])\n",
    "\n",
    "print(\"\\n\\nTest Set :\\n----------------\\n\")\n",
    "print(\"X = \\n\",X_test[:5])\n",
    "print(\"y = \\n\", y_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Training set is (1304, 4)\n",
      "Shape of Testing set is (327, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of Training set is {X_train.shape}\")\n",
    "print(f\"Shape of Testing set is {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Decision Tree Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad0a116c536f489daf6ab3c9c317bcd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ToggleButtons(description='Number of features for the best split :', options=('log2', 'sqrt', 'auto'), style=T…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b4cefda83fa4b2d8c478bb4b3b680a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='The maximum depth of the Tree. :', options=(10, 20, 30, 50), style=DescriptionStyle(desc…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c889f6b66da460da7369c640ceb3e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='The minimum sample split of the Tree. :', options=(100, 200, 300, 500), style=Descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import decision tree library\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# configure params for the model.\n",
    "max_feat_wig = widgets.ToggleButtons(options=['log2', 'sqrt', 'auto'],\n",
    "                                    description='Number of features for the best split :',\n",
    "                                    disabled=False,\n",
    "                                    style=style)\n",
    "\n",
    "display(max_feat_wig)\n",
    "\n",
    "max_depth_wig = widgets.Dropdown(options=[10, 20, 30, 50],\n",
    "                            description='The maximum depth of the Tree. :',\n",
    "                            style=style)\n",
    "\n",
    "display(max_depth_wig)\n",
    "\n",
    "min_split_wig = widgets.Dropdown(options=[100, 200, 300, 500],\n",
    "                            description='The minimum sample split of the Tree. :',\n",
    "                            style=style)\n",
    "\n",
    "display(min_split_wig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and Evaluate the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8XbYFyk8oCrH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions =  [3.4622449  0.         3.61913978 3.8861039  3.8861039  3.69\n",
      " 3.73025316 0.         3.61913978 3.69       3.73025316 3.5676\n",
      " 3.4622449  3.5676     3.95653333 3.69       3.4622449  3.92740741\n",
      " 3.61913978 3.7912069  3.7912069  3.8861039  0.         3.95653333\n",
      " 3.92740741 0.         3.95653333 3.61913978 3.61913978 3.92740741\n",
      " 3.89676471 0.         3.73025316 0.         3.95653333 3.61913978\n",
      " 3.73025316 3.89676471 3.5676     3.69       3.69       3.73025316\n",
      " 3.73025316 3.89676471 3.7912069  3.7912069  3.95653333 3.79470588\n",
      " 3.69       3.8861039  3.95653333 3.69       3.7912069  3.69\n",
      " 2.7        3.69       0.         3.7912069  3.7912069  3.5676\n",
      " 3.89676471 3.75734694 3.89676471 0.         3.4622449  3.8861039\n",
      " 3.79470588 3.61913978 3.5676     3.97375    3.8861039  3.65948718\n",
      " 3.69       3.8861039  3.69       4.02956522 3.69       3.5676\n",
      " 3.92740741 3.69       3.73025316 3.92740741 3.92740741 3.8861039\n",
      " 3.8861039  3.35153846 3.7912069  0.         3.92740741 3.95653333\n",
      " 3.7912069  3.69       0.         3.7912069  0.         3.5676\n",
      " 3.5676     3.35153846 3.75734694 3.69       3.69       3.61913978\n",
      " 3.73025316 3.79470588 3.7912069  3.5676     3.61913978 3.69\n",
      " 3.92740741 3.7912069  3.914      3.7912069  3.69       3.89676471\n",
      " 0.         3.8861039  3.35153846 3.92740741 3.69       3.61913978\n",
      " 3.92740741 0.         3.7912069  3.7912069  3.5676     3.65948718\n",
      " 3.8861039  3.95653333 3.7912069  3.8861039  3.7912069  0.\n",
      " 3.65948718 3.92740741 3.61913978 3.73025316 3.7912069  3.5676\n",
      " 3.7912069  3.75734694 3.8861039  3.79470588 3.61913978 0.\n",
      " 3.92740741 2.89714286 3.95653333 3.79470588 3.92740741 3.4622449\n",
      " 2.85285714 0.         0.         3.69       0.         3.8861039\n",
      " 0.         0.         3.92740741 3.8861039  3.69       3.61913978\n",
      " 3.35153846 3.89676471 3.5676     3.89676471 3.69       3.61913978\n",
      " 3.65948718 3.92740741 3.7912069  3.61913978 3.8861039  3.35153846\n",
      " 3.69       3.92740741 3.95653333 3.79470588 3.35153846 3.95653333\n",
      " 3.65948718 3.69       3.75734694 3.69       0.         3.69\n",
      " 3.69       3.35153846 3.5676     3.92740741 0.         3.95653333\n",
      " 3.75734694 3.8861039  0.         3.89676471 3.69       3.69\n",
      " 3.79470588 3.61913978 3.79470588 3.79470588 3.79470588 3.79470588\n",
      " 3.92740741 3.8861039  3.75734694 0.         3.89676471 0.\n",
      " 3.5676     3.73025316 3.69       0.         3.8861039  3.914\n",
      " 0.         0.         3.69       3.69       3.7912069  3.5676\n",
      " 3.89676471 0.         3.69       0.         3.8861039  3.8861039\n",
      " 3.79470588 3.8861039  0.         3.4622449  3.7912069  0.\n",
      " 0.         3.73025316 3.4622449  3.95653333 3.73025316 4.02956522\n",
      " 3.61913978 3.69       3.7912069  3.73025316 3.79470588 3.95653333\n",
      " 0.         3.4622449  3.73025316 3.8861039  3.95653333 3.4622449\n",
      " 3.69       0.         3.73025316 3.95653333 3.89676471 3.95653333\n",
      " 3.69       3.8861039  3.69       0.         3.95653333 3.92740741\n",
      " 3.61913978 3.79470588 3.7912069  3.79470588 3.61913978 3.92740741\n",
      " 0.         3.92740741 3.5676     3.69       3.61913978 3.95653333\n",
      " 3.69       3.89676471 3.89676471 3.65948718 4.39666667 3.79470588\n",
      " 3.89676471 3.79470588 3.69       3.95653333 0.         3.73025316\n",
      " 3.73025316 3.5676     3.92740741 0.         0.         3.8861039\n",
      " 3.914      3.4622449  3.35153846 3.7912069  3.69       0.\n",
      " 3.95653333 3.7912069  0.         3.8861039  3.92740741 3.8861039\n",
      " 3.5676     3.89676471 3.5676     3.75734694 3.79470588 3.69\n",
      " 3.79470588 4.02956522 3.7912069  3.7912069  3.95653333 3.69\n",
      " 3.69       3.79470588 3.75734694 3.7912069  3.69       3.92740741\n",
      " 0.         3.35153846 3.95653333]\n"
     ]
    }
   ],
   "source": [
    "# Train the Regressor with training set\n",
    "regressor = DecisionTreeRegressor(max_features=max_feat_wig.value,\n",
    "                                  max_depth=max_depth_wig.value,\n",
    "                                  min_samples_split=min_split_wig.value)\n",
    "\n",
    "#fit the linear model\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "#7 predict the outcome of test sets\n",
    "y_Pred = regressor.predict(X_test)\n",
    "print(\"\\nPredictions = \", y_Pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZAwiJVWuoHEX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------\n",
      "RMLSE Score =  0.9560145037636976\n",
      "\n",
      "Actual vs Predicted Scores \n",
      "------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Abs. Error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.13</td>\n",
       "      <td>3.462245</td>\n",
       "      <td>0.332245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.82</td>\n",
       "      <td>3.619140</td>\n",
       "      <td>0.799140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.91</td>\n",
       "      <td>3.886104</td>\n",
       "      <td>0.023896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.38</td>\n",
       "      <td>3.886104</td>\n",
       "      <td>0.493896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.25</td>\n",
       "      <td>3.690000</td>\n",
       "      <td>0.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.82</td>\n",
       "      <td>3.730253</td>\n",
       "      <td>0.089747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.49</td>\n",
       "      <td>3.619140</td>\n",
       "      <td>0.129140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.00</td>\n",
       "      <td>3.690000</td>\n",
       "      <td>1.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.40</td>\n",
       "      <td>3.730253</td>\n",
       "      <td>0.330253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.53</td>\n",
       "      <td>3.567600</td>\n",
       "      <td>0.037600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.89</td>\n",
       "      <td>3.462245</td>\n",
       "      <td>0.427755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.64</td>\n",
       "      <td>3.567600</td>\n",
       "      <td>0.072400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.84</td>\n",
       "      <td>3.956533</td>\n",
       "      <td>0.116533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.17</td>\n",
       "      <td>3.690000</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.71</td>\n",
       "      <td>3.462245</td>\n",
       "      <td>0.247755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.31</td>\n",
       "      <td>3.927407</td>\n",
       "      <td>0.382593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.90</td>\n",
       "      <td>3.619140</td>\n",
       "      <td>0.280860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.00</td>\n",
       "      <td>3.791207</td>\n",
       "      <td>0.791207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>3.83</td>\n",
       "      <td>3.791207</td>\n",
       "      <td>0.038793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>3.43</td>\n",
       "      <td>3.886104</td>\n",
       "      <td>0.456104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3.98</td>\n",
       "      <td>3.956533</td>\n",
       "      <td>0.023467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>3.81</td>\n",
       "      <td>3.927407</td>\n",
       "      <td>0.117407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>3.84</td>\n",
       "      <td>3.956533</td>\n",
       "      <td>0.116533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>3.72</td>\n",
       "      <td>3.619140</td>\n",
       "      <td>0.100860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2.97</td>\n",
       "      <td>3.619140</td>\n",
       "      <td>0.649140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4.12</td>\n",
       "      <td>3.927407</td>\n",
       "      <td>0.192593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>3.79</td>\n",
       "      <td>3.791207</td>\n",
       "      <td>0.001207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>4.10</td>\n",
       "      <td>3.690000</td>\n",
       "      <td>0.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>4.28</td>\n",
       "      <td>3.956533</td>\n",
       "      <td>0.323467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>3.67</td>\n",
       "      <td>3.791207</td>\n",
       "      <td>0.121207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>3.94</td>\n",
       "      <td>3.886104</td>\n",
       "      <td>0.053896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>4.35</td>\n",
       "      <td>3.927407</td>\n",
       "      <td>0.422593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>3.94</td>\n",
       "      <td>3.886104</td>\n",
       "      <td>0.053896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>3.43</td>\n",
       "      <td>3.567600</td>\n",
       "      <td>0.137600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>4.08</td>\n",
       "      <td>3.896765</td>\n",
       "      <td>0.183235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>3.61</td>\n",
       "      <td>3.567600</td>\n",
       "      <td>0.042400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>4.47</td>\n",
       "      <td>3.757347</td>\n",
       "      <td>0.712653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>3.83</td>\n",
       "      <td>3.794706</td>\n",
       "      <td>0.035294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>3.15</td>\n",
       "      <td>3.690000</td>\n",
       "      <td>0.540000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>3.96</td>\n",
       "      <td>3.794706</td>\n",
       "      <td>0.165294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>3.71</td>\n",
       "      <td>4.029565</td>\n",
       "      <td>0.319565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>4.25</td>\n",
       "      <td>3.791207</td>\n",
       "      <td>0.458793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>3.50</td>\n",
       "      <td>3.791207</td>\n",
       "      <td>0.291207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>4.04</td>\n",
       "      <td>3.956533</td>\n",
       "      <td>0.083467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>4.00</td>\n",
       "      <td>3.690000</td>\n",
       "      <td>0.310000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>3.52</td>\n",
       "      <td>3.690000</td>\n",
       "      <td>0.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>4.39</td>\n",
       "      <td>3.794706</td>\n",
       "      <td>0.595294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>3.77</td>\n",
       "      <td>3.757347</td>\n",
       "      <td>0.012653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>4.15</td>\n",
       "      <td>3.791207</td>\n",
       "      <td>0.358793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>2.96</td>\n",
       "      <td>3.690000</td>\n",
       "      <td>0.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>4.13</td>\n",
       "      <td>3.927407</td>\n",
       "      <td>0.202593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>4.05</td>\n",
       "      <td>3.351538</td>\n",
       "      <td>0.698462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>4.14</td>\n",
       "      <td>3.956533</td>\n",
       "      <td>0.183467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>327 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Actual  Predicted  Abs. Error\n",
       "0      3.13   3.462245    0.332245\n",
       "1      0.00   0.000000    0.000000\n",
       "2      2.82   3.619140    0.799140\n",
       "3      3.91   3.886104    0.023896\n",
       "4      4.38   3.886104    0.493896\n",
       "5      4.25   3.690000    0.560000\n",
       "6      3.82   3.730253    0.089747\n",
       "7      0.00   0.000000    0.000000\n",
       "8      3.49   3.619140    0.129140\n",
       "9      2.00   3.690000    1.690000\n",
       "10     3.40   3.730253    0.330253\n",
       "11     3.53   3.567600    0.037600\n",
       "12     3.89   3.462245    0.427755\n",
       "13     3.64   3.567600    0.072400\n",
       "14     3.84   3.956533    0.116533\n",
       "15     4.17   3.690000    0.480000\n",
       "16     3.71   3.462245    0.247755\n",
       "17     4.31   3.927407    0.382593\n",
       "18     3.90   3.619140    0.280860\n",
       "19     3.00   3.791207    0.791207\n",
       "20     3.83   3.791207    0.038793\n",
       "21     3.43   3.886104    0.456104\n",
       "22     0.00   0.000000    0.000000\n",
       "23     3.98   3.956533    0.023467\n",
       "24     3.81   3.927407    0.117407\n",
       "25     0.00   0.000000    0.000000\n",
       "26     3.84   3.956533    0.116533\n",
       "27     3.72   3.619140    0.100860\n",
       "28     2.97   3.619140    0.649140\n",
       "29     4.12   3.927407    0.192593\n",
       "..      ...        ...         ...\n",
       "297    3.79   3.791207    0.001207\n",
       "298    4.10   3.690000    0.410000\n",
       "299    0.00   0.000000    0.000000\n",
       "300    4.28   3.956533    0.323467\n",
       "301    3.67   3.791207    0.121207\n",
       "302    0.00   0.000000    0.000000\n",
       "303    3.94   3.886104    0.053896\n",
       "304    4.35   3.927407    0.422593\n",
       "305    3.94   3.886104    0.053896\n",
       "306    3.43   3.567600    0.137600\n",
       "307    4.08   3.896765    0.183235\n",
       "308    3.61   3.567600    0.042400\n",
       "309    4.47   3.757347    0.712653\n",
       "310    3.83   3.794706    0.035294\n",
       "311    3.15   3.690000    0.540000\n",
       "312    3.96   3.794706    0.165294\n",
       "313    3.71   4.029565    0.319565\n",
       "314    4.25   3.791207    0.458793\n",
       "315    3.50   3.791207    0.291207\n",
       "316    4.04   3.956533    0.083467\n",
       "317    4.00   3.690000    0.310000\n",
       "318    3.52   3.690000    0.170000\n",
       "319    4.39   3.794706    0.595294\n",
       "320    3.77   3.757347    0.012653\n",
       "321    4.15   3.791207    0.358793\n",
       "322    2.96   3.690000    0.730000\n",
       "323    4.13   3.927407    0.202593\n",
       "324    0.00   0.000000    0.000000\n",
       "325    4.05   3.351538    0.698462\n",
       "326    4.14   3.956533    0.183467\n",
       "\n",
       "[327 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating score from Root Mean Log Squared Error\n",
    "def rmlse(y_test, y_pred):\n",
    "    error = np.square(np.log10(y_pred +1) - np.log10(y_test +1)).mean() ** 0.5\n",
    "    score = 1 - error\n",
    "    return score\n",
    "\n",
    "# Printing the score\n",
    "print(\"\\n----------------------------\\nRMLSE Score = \", rmlse(y_test, y_Pred))\n",
    "\n",
    "#9 Comparing Actual and Predicted Salaries for he test set\n",
    "print(\"\\nActual vs Predicted Scores \\n------------------------------\\n\")\n",
    "error_df = pd.DataFrame({\"Actual\" : y_test,\n",
    "                         \"Predicted\" : y_Pred,\n",
    "                         \"Abs. Error\" : np.abs(y_test - y_Pred)})\n",
    "\n",
    "error_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual vs. Predicted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting Actual observation vs Predictions\n",
    "plt.scatter(y_test, y_Pred, s = 70)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "#plt.legend();\n",
    "plt.grid();\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "LinearRegression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
